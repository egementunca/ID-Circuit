"""
Identity Circuit Factory Manager.
Main orchestrator for generating, unrolling, and managing identity circuits.
"""

import logging
import time
from typing import List, Dict, Optional, Tuple, Any
from dataclasses import dataclass

from .database import CircuitDatabase
from .seed_generator import SeedGenerator
from .unroller import CircuitUnroller
from .post_processor import PostProcessor
from .debris_cancellation import DebrisCancellationManager
from .ml_features import MLFeatureManager
from .job_queue import JobQueueManager

logger = logging.getLogger(__name__)

@dataclass
class FactoryConfig:
    """Configuration for the identity factory."""
    db_path: str = "identity_circuits.db"
    max_inverse_gates: int = 40
    max_equivalents: int = 10000
    sat_solver: str = "minisat-gh"
    log_level: str = "INFO"
    enable_post_processing: bool = True
    enable_unrolling: bool = True
    enable_debris_analysis: bool = True
    enable_ml_features: bool = True
    enable_job_queue: bool = True
    max_workers: int = 4
    max_debris_gates: int = 5
    redis_url: str = "redis://localhost:6379"
    parquet_storage: bool = False

@dataclass
class FactoryStats:
    """Statistics about the factory operations."""
    total_dim_groups: int = 0
    total_circuits: int = 0
    total_representatives: int = 0
    total_equivalents: int = 0
    total_simplifications: int = 0
    total_debris_analyses: int = 0
    total_ml_analyses: int = 0
    active_jobs: int = 0
    generation_time: float = 0.0
    unroll_time: float = 0.0
    post_process_time: float = 0.0
    debris_analysis_time: float = 0.0
    ml_analysis_time: float = 0.0

class IdentityFactory:
    """Main factory for identity circuit generation and management."""
    
    def __init__(self, config: Optional[FactoryConfig] = None):
        self.config = config or FactoryConfig()
        self._setup_logging()
        
        # Initialize database
        self.db = CircuitDatabase(self.config.db_path)
        
        # Initialize components
        self.seed_generator = SeedGenerator(self.db, self.config.max_inverse_gates)
        self.unroller = CircuitUnroller(self.db, self.config.max_equivalents)
        self.post_processor = PostProcessor(self.db)
        self.debris_manager = DebrisCancellationManager(self.db, self.config.max_debris_gates)
        self.ml_manager = MLFeatureManager(self.db)
        
        # Initialize job queue if enabled
        self.job_queue = None
        if self.config.enable_job_queue:
            try:
                self.job_queue = JobQueueManager(
                    database=self.db,
                    redis_url=self.config.redis_url,
                    max_workers=self.config.max_workers
                )
                self._register_job_handlers()
            except Exception as e:
                logger.warning(f"Failed to initialize job queue: {e}")
                self.job_queue = None
        
        logger.info("IdentityFactory initialized successfully")
    
    def _setup_logging(self):
        """Set up logging configuration."""
        level = getattr(logging, self.config.log_level.upper())
        logging.basicConfig(level=level)
        logger.setLevel(level)
    
    def _register_job_handlers(self):
        """Register job handlers with the job queue."""
        if self.job_queue:
            self.job_queue.register_handler('seed_generation', self._handle_seed_generation_job)
            self.job_queue.register_handler('unrolling', self._handle_unrolling_job)
            self.job_queue.register_handler('post_processing', self._handle_post_processing_job)
            self.job_queue.register_handler('debris_analysis', self._handle_debris_analysis_job)
            self.job_queue.register_handler('ml_feature_extraction', self._handle_ml_feature_job)
    
    async def _handle_seed_generation_job(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """Handle seed generation job."""
        width = params['width']
        gate_count = params['gate_count']
        result = self.seed_generator.generate_seed(width, gate_count)
        return result.__dict__
    
    async def start_job_queue(self):
        """Start the job queue workers."""
        if self.job_queue:
            await self.job_queue.start_workers()
    
    async def stop_job_queue(self):
        """Stop the job queue workers."""
        if self.job_queue:
            await self.job_queue.stop_workers()
    
    def generate_identity_circuit(self, width: int, gate_count: int, 
                                enable_unrolling: bool = True,
                                enable_post_processing: bool = True,
                                enable_debris_analysis: bool = True,
                                enable_ml_analysis: bool = True,
                                use_job_queue: bool = False,
                                **kwargs) -> Dict[str, Any]:
        """
        Generate a complete identity circuit with optional processing steps.
        
        Args:
            width: Number of qubits
            gate_count: Number of gates in forward circuit
            enable_unrolling: Whether to generate equivalent circuits
            enable_post_processing: Whether to apply simplifications
            enable_debris_analysis: Whether to analyze for debris cancellation
            enable_ml_analysis: Whether to extract ML features
            use_job_queue: Whether to use distributed processing
            **kwargs: Additional parameters
            
        Returns:
            Dictionary with generation results and metadata
        """
        start_time = time.time()
        result = {
            'success': False,
            'width': width,
            'gate_count': gate_count,
            'total_time': 0.0
        }
        
        try:
            logger.info(f"Generating identity circuit ({width}, {gate_count})")
            
            # Step 1: Generate seed circuit
            # Filter kwargs to only include parameters that generate_seed accepts
            seed_kwargs = {
                k: v for k, v in kwargs.items() 
                if k in ['max_attempts', 'sequential']
            }
            seed_result = self.seed_generator.generate_seed(width, gate_count, **seed_kwargs)
            result['seed_generation'] = seed_result
            
            if not seed_result.success:
                result['error'] = seed_result.error_message
                return result
            
            circuit_id = seed_result.circuit_id
            dim_group_id = seed_result.dim_group_id
            representative_id = seed_result.representative_id
            
            # Step 2: Unroll to generate equivalents (if enabled and representative was created)
            if enable_unrolling and representative_id:
                if use_job_queue and self.job_queue:
                    # Submit unrolling job (would need async version)
                    # For now, just mark as queued without actual submission
                    result['unrolling'] = {'status': 'queued'}
                else:
                    unroll_result = self.unroller.unroll_dimension_group(dim_group_id)
                    result['unrolling'] = unroll_result
            
            # Step 3: Post-processing (if enabled)
            if enable_post_processing and dim_group_id:
                if use_job_queue and self.job_queue:
                    # Submit post-processing job (would need async version)
                    result['post_processing'] = {'status': 'queued'}
                else:
                    post_result = self.post_processor.simplify_dimension_group(dim_group_id)
                    result['post_processing'] = post_result
                    result['successful_simplifications'] = len([r for r in post_result.values() if r.success])
            
            # Step 4: Debris analysis (if enabled)
            if enable_debris_analysis and circuit_id and dim_group_id:
                if use_job_queue and self.job_queue:
                    # Submit debris analysis job (would need async version)
                    result['debris_analysis'] = {'status': 'queued'}
                else:
                    debris_result = self.debris_manager.analyze_dim_group_representative(dim_group_id, circuit_id)
                    result['debris_analysis'] = debris_result
            
            # Step 5: ML feature extraction (if enabled)
            if enable_ml_analysis and circuit_id and dim_group_id:
                if use_job_queue and self.job_queue:
                    # Submit ML feature extraction job (would need async version)
                    result['ml_analysis'] = {'status': 'queued'}
                else:
                    circuit_record = self.db.get_circuit(circuit_id)
                    if circuit_record:
                        circuit = self._record_to_circuit(circuit_record)
                        ml_result = self.ml_manager.analyze_circuit(circuit_id, dim_group_id, circuit)
                        result['ml_analysis'] = ml_result
            
            result['success'] = True
            
        except Exception as e:
            logger.error(f"Circuit generation failed: {e}")
            result['error'] = str(e)
        
        finally:
            result['total_time'] = time.time() - start_time
        
        return result
    
    def _record_to_circuit(self, record):
        """Helper to convert a CircuitRecord from the DB to a sat_revsynth.Circuit object."""
        from sat_revsynth.circuit.circuit import Circuit
        
        circuit = Circuit(record.width)
        for gate in record.gates:
            controls, target = gate
            if len(controls) == 0:
                circuit = circuit.x(target)
            elif len(controls) == 1:
                circuit = circuit.cx(controls[0], target)
            elif len(controls) == 2:
                circuit = circuit.mcx(controls, target)
            else:
                circuit = circuit.mcx(controls, target)
        return circuit
    
    def _handle_unrolling_job(self, parameters: Dict[str, Any]) -> Dict[str, Any]:
        """Handle unrolling job."""
        dim_group_id = parameters['dim_group_id']
        unroll_types = parameters.get('unroll_types')
        
        result = self.unroller.unroll_dimension_group(dim_group_id, unroll_types)
        return result.__dict__
    
    def _handle_post_processing_job(self, parameters: Dict[str, Any]) -> Dict[str, Any]:
        """Handle post-processing job."""
        dim_group_id = parameters['dim_group_id']
        simplification_types = parameters.get('simplification_types')
        
        results = self.post_processor.simplify_dimension_group(
            dim_group_id, simplification_types
        )
        
        # Convert results to serializable format
        serializable_results = {}
        for circuit_id, result in results.items():
            serializable_results[str(circuit_id)] = result.__dict__
        
        return serializable_results
    
    def _handle_debris_analysis_job(self, parameters: Dict[str, Any]) -> Dict[str, Any]:
        """Handle debris analysis job."""
        dim_group_id = parameters['dim_group_id']
        circuit_id = parameters['circuit_id']
        
        result = self.debris_manager.analyze_dim_group_representative(dim_group_id, circuit_id)
        return result or {}
    
    def _handle_ml_feature_job(self, parameters: Dict[str, Any]) -> Dict[str, Any]:
        """Handle ML feature extraction job."""
        circuit_id = parameters['circuit_id']
        dim_group_id = parameters['dim_group_id']
        
        circuit_record = self.db.get_circuit(circuit_id)
        if not circuit_record:
            return {'error': 'Circuit not found'}
        
        circuit = self._record_to_circuit(circuit_record)
        result = self.ml_manager.analyze_circuit(circuit_id, dim_group_id, circuit)
        return result
    
    def batch_generate(self, dimensions: List[Tuple[int, int]], 
                      use_job_queue: bool = False,
                      **kwargs) -> Dict[Tuple[int, int], Dict[str, Any]]:
        """
        Generate multiple identity circuits for different dimensions.
        
        Args:
            dimensions: List of (width, gate_count) tuples
            use_job_queue: Whether to use distributed processing
            **kwargs: Additional parameters for generation
            
        Returns:
            Dictionary mapping dimensions to generation results
        """
        results = {}
        
        logger.info(f"Batch generating {len(dimensions)} dimension groups")
        
        for width, gate_count in dimensions:
            logger.info(f"Processing dimension ({width}, {gate_count})")
            
            try:
                result = self.generate_identity_circuit(
                    width, gate_count, 
                    use_job_queue=use_job_queue, 
                    **kwargs
                )
                results[(width, gate_count)] = result
                
            except Exception as e:
                logger.error(f"Failed to generate ({width}, {gate_count}): {e}")
                results[(width, gate_count)] = {
                    'success': False,
                    'error': str(e),
                    'width': width,
                    'gate_count': gate_count
                }
        
        return results
    
    def get_factory_stats(self) -> FactoryStats:
        """Get comprehensive factory statistics."""
        db_stats = self.db.get_database_stats()
        
        return FactoryStats(
            total_dim_groups=db_stats.get('total_dim_groups', 0),
            total_circuits=db_stats.get('total_circuits', 0),
            total_representatives=db_stats.get('total_representatives', 0),
            total_equivalents=db_stats.get('total_equivalents', 0),
            total_simplifications=0,  # Would need to be tracked
            total_debris_analyses=db_stats.get('debris_cancellations', 0),
            total_ml_analyses=db_stats.get('ml_features', 0),
            active_jobs=sum(db_stats.get('job_status_counts', {}).values()),
            generation_time=self.seed_generator.total_generation_time,
            unroll_time=self.unroller.total_unroll_time,
            post_process_time=0.0,  # Would need to be tracked
            debris_analysis_time=0.0,  # Would need to be tracked
            ml_analysis_time=0.0  # Would need to be tracked
        )
    
    def get_dimension_group_analysis(self, dim_group_id: int) -> Dict[str, Any]:
        """Get comprehensive analysis of a dimension group."""
        dim_group = self.db.get_dim_group_by_id(dim_group_id)
        if not dim_group:
            return {'error': 'Dimension group not found'}
        
        # Get representatives
        representatives = self.db.get_representatives_for_dim_group(dim_group_id)
        
        # Get all equivalents
        equivalents = self.db.get_all_equivalents_for_dim_group(dim_group_id)
        
        # Analyze gate compositions
        composition_analysis = self._analyze_gate_compositions(equivalents)
        
        analysis = {
            'dim_group_id': dim_group_id,
            'width': dim_group.width,
            'gate_count': dim_group.gate_count,
            'circuit_count': dim_group.circuit_count,
            'total_equivalents': len(equivalents),
            'is_processed': dim_group.is_processed,
            'representatives': [
                {
                    'id': rep.id,
                    'circuit_id': rep.circuit_id,
                    'gate_composition': rep.gate_composition,
                    'is_primary': rep.is_primary
                }
                for rep in representatives
            ],
            'equivalents': {
                'total': len(equivalents),
                'by_unroll_type': {},
                'by_gate_composition': composition_analysis
            }
        }
        
        # Group equivalents by unroll type
        for equiv in equivalents:
            unroll_type = equiv.get('unroll_type', 'unknown')
            if unroll_type not in analysis['equivalents']['by_unroll_type']:
                analysis['equivalents']['by_unroll_type'][unroll_type] = 0
            analysis['equivalents']['by_unroll_type'][unroll_type] += 1
        
        return analysis
    
    def _analyze_gate_compositions(self, equivalents: List[Dict[str, Any]]) -> Dict[str, int]:
        """Analyze gate compositions in equivalent circuits."""
        compositions = {}
        for equiv in equivalents:
            comp = equiv.get('gate_composition')
            if comp:
                comp_str = str(comp)
                compositions[comp_str] = compositions.get(comp_str, 0) + 1
        return compositions
    
    def export_dimension_group(self, dim_group_id: int, 
                             output_path: str) -> bool:
        """Export a dimension group to a file."""
        try:
            analysis = self.get_dimension_group_analysis(dim_group_id)
            if 'error' in analysis:
                return False
            
            import json
            with open(output_path, 'w') as f:
                json.dump(analysis, f, indent=2, default=str)
            
            logger.info(f"Exported dimension group {dim_group_id} to {output_path}")
            return True
            
        except Exception as e:
            logger.error(f"Export failed: {e}")
            return False
    
    def import_dimension_group(self, import_path: str) -> bool:
        """Import a dimension group from a file."""
        try:
            import json
            with open(import_path, 'r') as f:
                data = json.load(f)
            
            # This would implement the actual import logic
            # For now, just log the attempt
            logger.info(f"Imported dimension group from {import_path}")
            return True
            
        except Exception as e:
            logger.error(f"Import failed: {e}")
            return False
    
    def cleanup_old_circuits(self, max_age_days: int = 30) -> int:
        """Clean up old circuits and associated data."""
        # This would implement cleanup logic
        # For now, return 0
        logger.info(f"Cleanup completed (placeholder)")
        return 0
    
    def get_recommended_dimensions(self, target_width: int, 
                                 max_gate_count: int = 20) -> List[Tuple[int, int]]:
        """Get recommended dimensions for exploration."""
        recommendations = []
        
        # Simple recommendation logic
        for gate_count in range(2, max_gate_count + 1, 2):
            recommendations.append((target_width, gate_count))
        
        return recommendations[:10]  # Limit to 10 recommendations 